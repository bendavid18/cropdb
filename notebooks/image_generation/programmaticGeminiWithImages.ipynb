{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dir   = '../../data/input/'\n",
    "input_data_df_dir = '../../data/output/Image_df/'\n",
    "\n",
    "output_dir = '../../data/output/Image_df/'\n",
    "\n",
    "input_file_name = 'Crop_Varieties.xlsx'\n",
    "\n",
    "now = datetime.now()\n",
    "formatted_date = now.strftime('%Y%m%d%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'model': 'gemini-1.5-pro-002'   # \"gemini-1.5-flash\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ['GOOGLE_TENDTEST_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_directory_if_exists(directory_path):\n",
    "    if os.path.exists(directory_path):\n",
    "        shutil.rmtree(directory_path)\n",
    "        print(f\"Deleted directory: {directory_path}\")\n",
    "    else:\n",
    "        print(f\"Directory does not exist: {directory_path}\")\n",
    "\n",
    "def load_crop_data(input_data_dir, input_file_name):\n",
    "    # Construct the full path to the Excel file\n",
    "    excel_file_path = os.path.join(input_data_dir, input_file_name)\n",
    "    \n",
    "    # Load the Excel file\n",
    "    excel_data = pd.ExcelFile(excel_file_path)\n",
    "    \n",
    "    # Initialize a dictionary to store the crop names and their varieties\n",
    "    crop_varieties = {}\n",
    "    \n",
    "    # Iterate through each sheet in the Excel file\n",
    "    for sheet_name in excel_data.sheet_names:\n",
    "        # Read the sheet into a DataFrame without header\n",
    "        df = pd.read_excel(excel_file_path, sheet_name=sheet_name, header=None)\n",
    "        \n",
    "        # Assuming the varieties are listed in the first column\n",
    "        varieties = df.iloc[:, 0].tolist()\n",
    "        \n",
    "        # Store the crop name (sheet name) and its varieties in the dictionary\n",
    "        crop_varieties[sheet_name] = varieties\n",
    "    \n",
    "    return crop_varieties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Radishes': ['French Breakfast'],\n",
       " 'Beets': ['Avalanche', 'Badger Flame'],\n",
       " 'Dill': ['Ella'],\n",
       " 'Tomatoes': ['Sun Gold'],\n",
       " 'Peppers': ['Jimmy Nardello'],\n",
       " 'Cabbage': ['Kaitlin']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Load crop data from Excel\n",
    "crop_varieties = load_crop_data(input_data_dir, input_file_name)\n",
    "crop_varieties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_dataframe(input_dir, crop_name, variety):\n",
    "    # Construct the path to the DataFrame file\n",
    "    dataframe_path = os.path.join(input_dir, crop_name, f\"{variety}.xlsx\")\n",
    "    \n",
    "    # Load the DataFrame from the specified path\n",
    "    df = pd.read_excel(dataframe_path, sheet_name='google_search')\n",
    "    \n",
    "    # Extract the 'filename' column into a list called image_paths\n",
    "    image_paths = df['filename'].tolist()\n",
    "    \n",
    "    # Open each image using PIL.Image.open and store them in a list called images\n",
    "    images = [Image.open(image_path) for image_path in image_paths]\n",
    "    \n",
    "    # Return the list of images\n",
    "    return images\n",
    "\n",
    "# Example usage\n",
    "\n",
    "crop_name = 'Beets'\n",
    "variety = 'Badger Flame'\n",
    "# crop_name = 'Cabbage'\n",
    "# variety = 'Kaitlin'\n",
    "\n",
    "images = load_images_from_dataframe(input_dir = input_data_df_dir, crop_name = crop_name, variety = variety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template = '''\n",
    "# # Introduction:\n",
    "\n",
    "# You're an expert vegetable, flower, and plant photographer that can interpret images and output a description that captures \n",
    "# lighting, detail, and nuances of realistic still life photography.\n",
    "\n",
    "# # Step 1:\n",
    "\n",
    "# You will be provided with several images. Analyze them and select the top 3 images where the {variety} {crop_name} is the primary subject, \n",
    "# well-lit, and in focus.  \n",
    "\n",
    "# Choose images that show the {variety} {crop_name} from multiple angles and with minimal background distractions.\n",
    "\n",
    "# List the file names or image numbers of these images.\n",
    "\n",
    "# # Step 2:  Description Synthesis\n",
    "\n",
    "# From the images you selected, as an expert vegetable, flower, and plant photographer, create detailed descriptions of each image. \n",
    "# Pay close attention to the shape, size, color, texture, and any unique markings or patterns on the {variety} {crop_name}. Consider how the \n",
    "# light interacts with the surface and describe any shadows or highlights.\n",
    "\n",
    "# Don't include the individual descriptions in the output, but rather use them as input for Step 3. \n",
    "\n",
    "# # Step 3: Reduce to Single Fruit, Vegetable or Flower\n",
    "\n",
    "# Now that you're an expert in the visual attributes of {variety} {crop_name}, provide a detailed description of a single, typical \n",
    "# {variety} {crop_name} on a white background, without describing the variety itself.  \n",
    "\n",
    "# This description will be used as an input to Imagen3, so tailor your response accordingly. Use evocative language that captures the \n",
    "# essence of the {variety} {crop_name} and include descriptive terms related to light, shadow, and texture that Imagen3 can effectively \n",
    "# interpret.\n",
    "\n",
    "# # Step 4: Output Format\n",
    "\n",
    "# Finally, present your response in a JSON format with the following keys:\n",
    "\n",
    "# * `CROP_NAME`: equal to the value of {crop_name}\n",
    "# * `VARIETY`: equal to the value of {variety}\n",
    "# * `VALID_IMAGES`: the result of Step 1 (list of the image number indices. Indices should start from 1)\n",
    "# * `PROMPT`: the result of Step 3 (the detailed description)\n",
    "\n",
    "# Data to follow below:\n",
    "\n",
    "# [CROP_NAME] = {crop_name}\n",
    "# [VARIETY] = {variety}\n",
    "# '''\n",
    "\n",
    "# prompt = prompt_template.format(crop_name=crop_name, variety=variety)\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Introduction:\n",
      "\n",
      "You're an expert vegetable, flower, and plant photographer that can interpret images and output a description that captures \n",
      "lighting, detail, and nuances of realistic still life photography.\n",
      "\n",
      "# Step 1:\n",
      "\n",
      "You will be provided with several images. Analyze them and select the top 5 images where the Badger Flame Beets is the primary subject, \n",
      "well-lit, in focus and is not a cross-section or part of the object. \n",
      "\n",
      "Choose images that show the Badger Flame Beets from multiple angles and with minimal background distractions.\n",
      "\n",
      "List the file names or image numbers of these images.\n",
      "\n",
      "# Step 2:  Description Synthesis\n",
      "\n",
      "From the images you selected, as an expert vegetable, flower, and plant photographer, create detailed descriptions of each image. \n",
      "Pay close attention to the shape, size, color, texture, and any unique markings or patterns on the Badger Flame Beets. Consider how the \n",
      "light interacts with the surface and describe any shadows or highlights.\n",
      "\n",
      "Don't include the individual descriptions in the output, but rather use them as input for Step 3. \n",
      "\n",
      "# Step 3: Reduce to Single Fruit, Vegetable or Flower\n",
      "\n",
      "Now that you're an expert in the visual attributes of Badger Flame Beets, provide a detailed description of a single, typical \n",
      "Badger Flame Beets on a white background, without describing the variety.  \n",
      "\n",
      "This description will be used as an input to Imagen3, so tailor your response accordingly. Use evocative language that captures the \n",
      "essence of the Badger Flame Beets and include descriptive terms related to shape, size, color, texture, and any unique markings or patterns\n",
      "as well as light and shadow that Imagen3 can effectively interpret.\n",
      "\n",
      "Shape is huge component of the description.  Describe the shape of the Badger Flame Beets in detail.  \n",
      "Include any unique markings or patterns on the Badger Flame Beets.\n",
      "\n",
      "Highlight any differences between the Badger Flame Beets and other varieties of the same crop so that Imagen3 can distinguish between them.\n",
      "\n",
      "When appropriate, the description should be of a whole Single Fruit, Vegetable or Flower and not a cross-section or part of the object.\n",
      "\n",
      "# Step 4: Output Format\n",
      "\n",
      "Finally, present your response in a JSON format with the following keys:\n",
      "\n",
      "* `CROP_NAME`: equal to the value of Beets\n",
      "* `VARIETY`: equal to the value of Badger Flame\n",
      "* `VALID_IMAGES`: the result of Step 1 (list of the image number indices. Indices should start from 1)\n",
      "* `PROMPT`: the result of Step 3 (the detailed description)\n",
      "\n",
      "Data to follow below:\n",
      "\n",
      "[CROP_NAME] = Beets\n",
      "[VARIETY] = Badger Flame\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_template = '''\n",
    "# Introduction:\n",
    "\n",
    "You're an expert vegetable, flower, and plant photographer that can interpret images and output a description that captures \n",
    "lighting, detail, and nuances of realistic still life photography.\n",
    "\n",
    "# Step 1:\n",
    "\n",
    "You will be provided with several images. Analyze them and select the top 5 images where the {variety} {crop_name} is the primary subject, \n",
    "well-lit, in focus and is not a cross-section or part of the object. \n",
    "\n",
    "Choose images that show the {variety} {crop_name} from multiple angles and with minimal background distractions.\n",
    "\n",
    "List the file names or image numbers of these images.\n",
    "\n",
    "# Step 2:  Description Synthesis\n",
    "\n",
    "From the images you selected, as an expert vegetable, flower, and plant photographer, create detailed descriptions of each image. \n",
    "Pay close attention to the shape, size, color, texture, and any unique markings or patterns on the {variety} {crop_name}. Consider how the \n",
    "light interacts with the surface and describe any shadows or highlights.\n",
    "\n",
    "Don't include the individual descriptions in the output, but rather use them as input for Step 3. \n",
    "\n",
    "# Step 3: Reduce to Single Fruit, Vegetable or Flower\n",
    "\n",
    "Now that you're an expert in the visual attributes of {variety} {crop_name}, provide a detailed description of a single, typical \n",
    "{variety} {crop_name} on a white background, without describing the variety.  \n",
    "\n",
    "This description will be used as an input to Imagen3, so tailor your response accordingly. Use evocative language that captures the \n",
    "essence of the {variety} {crop_name} and include descriptive terms related to shape, size, color, texture, and any unique markings or patterns\n",
    "as well as light and shadow that Imagen3 can effectively interpret.\n",
    "\n",
    "Shape is huge component of the description.  Describe the shape of the {variety} {crop_name} in detail.  \n",
    "Include any unique markings or patterns on the {variety} {crop_name}.\n",
    "\n",
    "Highlight any differences between the {variety} {crop_name} and other varieties of the same crop so that Imagen3 can distinguish between them.\n",
    "\n",
    "When appropriate, the description should be of a whole Single Fruit, Vegetable or Flower and not a cross-section or part of the object.\n",
    "\n",
    "# Step 4: Output Format\n",
    "\n",
    "Finally, present your response in a JSON format with the following keys:\n",
    "\n",
    "* `CROP_NAME`: equal to the value of {crop_name}\n",
    "* `VARIETY`: equal to the value of {variety}\n",
    "* `VALID_IMAGES`: the result of Step 1 (list of the image number indices. Indices should start from 1)\n",
    "* `PROMPT`: the result of Step 3 (the detailed description)\n",
    "\n",
    "Data to follow below:\n",
    "\n",
    "[CROP_NAME] = {crop_name}\n",
    "[VARIETY] = {variety}\n",
    "'''\n",
    "\n",
    "prompt = prompt_template.format(crop_name=crop_name, variety=variety)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate content using the model\n",
    "model = genai.GenerativeModel(params['model'])\n",
    "response = model.generate_content([prompt, *images], generation_config=genai.types.GenerationConfig(\n",
    "    temperature=0.0,\n",
    "    #max_output_tokens=1024\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to gemini_output sheet in variety.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CROP_NAME</th>\n",
       "      <th>VARIETY</th>\n",
       "      <th>VALID_IMAGES</th>\n",
       "      <th>PROMPT</th>\n",
       "      <th>PROMPT_TOKENS</th>\n",
       "      <th>COMPLETION_TOKENS</th>\n",
       "      <th>TOTAL_TOKENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beets</td>\n",
       "      <td>Badger Flame</td>\n",
       "      <td>[1, 3, 7]</td>\n",
       "      <td>A single Badger Flame beet rests on a bright w...</td>\n",
       "      <td>3151</td>\n",
       "      <td>250</td>\n",
       "      <td>3401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CROP_NAME       VARIETY VALID_IMAGES  \\\n",
       "0     Beets  Badger Flame    [1, 3, 7]   \n",
       "\n",
       "                                              PROMPT  PROMPT_TOKENS  \\\n",
       "0  A single Badger Flame beet rests on a bright w...           3151   \n",
       "\n",
       "   COMPLETION_TOKENS  TOTAL_TOKENS  \n",
       "0                250          3401  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single Badger Flame beet rests on a bright white background, its smooth skin gleaming under the light.  It is a vibrant, almost incandescent, orange-red, a color that deepens to ruby where the beet curves away from the light source.  The shape is a slightly elongated globe, wider at the top and tapering gently towards the root end.  This rounded, almost squat form distinguishes it from the more elongated shape of other beet varieties.  The beet's surface is subtly textured, not quite glossy, but with a soft sheen that reflects the light in delicate highlights.  Fine, almost invisible root hairs cling near the tapered bottom, where the beet narrows to meet the remnants of its taproot.  A faint network of pale, slightly raised veins traces a delicate pattern across the skin, adding a touch of complexity to its otherwise smooth surface.  The overall impression is one of vibrant color and earthy elegance, a jewel-toned root vegetable radiating a warm, inner glow.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Access the JSON response from the model\n",
    "json_response = response.candidates[0].content.parts[0].text\n",
    "\n",
    "# Strip off the leading and trailing triple backticks and newlines\n",
    "cleaned_json_response = json_response.strip('```json\\n')\n",
    "\n",
    "# Parse the JSON response with error handling\n",
    "try:\n",
    "    response_data = json.loads(cleaned_json_response)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decode error: {e}\")\n",
    "    response_data = {}\n",
    "\n",
    "# Access and print the token usage\n",
    "token_usage = response.usage_metadata\n",
    "\n",
    "# Prepare data for the new sheet\n",
    "data = {\n",
    "    'CROP_NAME': [response_data['CROP_NAME']],\n",
    "    'VARIETY': [response_data['VARIETY']],\n",
    "    'VALID_IMAGES': [response_data['VALID_IMAGES']],\n",
    "    'PROMPT': [response_data['PROMPT']],\n",
    "    'PROMPT_TOKENS': [token_usage.prompt_token_count],\n",
    "    'COMPLETION_TOKENS': [token_usage.candidates_token_count],\n",
    "    'TOTAL_TOKENS': [token_usage.total_token_count]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df_output = pd.DataFrame(data)\n",
    "\n",
    "# Write to a new sheet in the variety.xlsx file\n",
    "output_file = os.path.join(output_dir, crop_name, f\"{variety}.xlsx\")\n",
    "with pd.ExcelWriter(output_file, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "    df_output.to_excel(writer, sheet_name='gemini_output', index=False)\n",
    "\n",
    "print(\"Results written to gemini_output sheet in variety.xlsx\")\n",
    "display(df_output)\n",
    "print(df_output['PROMPT'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
